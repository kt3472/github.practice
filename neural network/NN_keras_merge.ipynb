{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x1 = np.array([range(100), range(311,411), range(100)])\n",
    "x2 = np.array([range(101,201), range(311,411), range(101,201)])\n",
    "y = np.array([range(501,601)]) #, range(711,811), range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 100)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99],\n",
       "       [311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,\n",
       "        324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336,\n",
       "        337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
       "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
       "        363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375,\n",
       "        376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388,\n",
       "        389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401,\n",
       "        402, 403, 404, 405, 406, 407, 408, 409, 410],\n",
       "       [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
       "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
       "        127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
       "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n",
       "        153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
       "        166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
       "        179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,\n",
       "        192, 193, 194, 195, 196, 197, 198, 199, 200],\n",
       "       [311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,\n",
       "        324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336,\n",
       "        337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
       "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
       "        363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375,\n",
       "        376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388,\n",
       "        389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401,\n",
       "        402, 403, 404, 405, 406, 407, 408, 409, 410],\n",
       "       [101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
       "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
       "        127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
       "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n",
       "        153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
       "        166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n",
       "        179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,\n",
       "        192, 193, 194, 195, 196, 197, 198, 199, 200]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513,\n",
       "        514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526,\n",
       "        527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539,\n",
       "        540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552,\n",
       "        553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565,\n",
       "        566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578,\n",
       "        579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591,\n",
       "        592, 593, 594, 595, 596, 597, 598, 599, 600]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.transpose(x1)\n",
    "y = np.transpose(y)\n",
    "x2 = np.transpose(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x1_train, x1_test, y_train, y_test = train_test_split(\n",
    "x1, y, random_state=66, test_size=0.4, shuffle=False\n",
    ")\n",
    "\n",
    "x1_val, x1_test, y_val, y_test = train_test_split(\n",
    "x1_test, y_test, random_state=66, test_size=0.5, shuffle=False\n",
    ")\n",
    "\n",
    "x2_train, x2_test = train_test_split(\n",
    "x2, random_state=66, test_size=0.4, shuffle=False\n",
    ")\n",
    "\n",
    "x2_val, x2_test= train_test_split(\n",
    "x2_test, random_state=66, test_size=0.5, shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = Input(shape=(3,))\n",
    "dense1 = Dense(100, activation='relu')(input1)\n",
    "dense1_2 = Dense(30)(dense1)\n",
    "dense1_3 = Dense(7)(dense1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input2 = Input(shape=(3,))\n",
    "dense2 = Dense(50, activation='relu')(input2)\n",
    "dense2_2 = Dense(7)(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.merge import concatenate\n",
    "merge1 = concatenate([dense1_3, dense2_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 14) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Dense(10)(merge1)\n",
    "model2 = Dense(5)(model1)\n",
    "output = Dense(1)(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 100)          400         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 30)           3030        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 50)           200         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 7)            217         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 7)            357         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 14)           0           dense_6[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 10)           150         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 5)            55          dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            6           dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 4,415\n",
      "Trainable params: 4,415\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs = [input1, input2], outputs = output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kt347\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60 samples, validate on 20 samples\n",
      "Epoch 1/100\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 19825.8266 - mse: 19825.8223 - val_loss: 4010.8875 - val_mse: 4010.8875\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 295.4706 - mse: 295.4707 - val_loss: 702.1355 - val_mse: 702.1356\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 0s 981us/step - loss: 151.8256 - mse: 151.8256 - val_loss: 742.3145 - val_mse: 742.3146\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 0s 931us/step - loss: 47.3973 - mse: 47.3973 - val_loss: 167.2989 - val_mse: 167.2989\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 0s 931us/step - loss: 9.7509 - mse: 9.7509 - val_loss: 109.0359 - val_mse: 109.0359\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 0s 981us/step - loss: 1.6963 - mse: 1.6963 - val_loss: 69.0603 - val_mse: 69.0603\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 0s 981us/step - loss: 0.0984 - mse: 0.0984 - val_loss: 48.9184 - val_mse: 48.9184\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.0297 - mse: 0.0297 - val_loss: 51.2879 - val_mse: 51.2879\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 46.4573 - val_mse: 46.4573\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 45.3942 - val_mse: 45.3942\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 45.5428 - val_mse: 45.5428\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 0s 981us/step - loss: 0.0124 - mse: 0.0124 - val_loss: 44.6705 - val_mse: 44.6705\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 0s 997us/step - loss: 0.0167 - mse: 0.0167 - val_loss: 44.2005 - val_mse: 44.2005\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.0100 - mse: 0.0100 - val_loss: 43.1301 - val_mse: 43.1301\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 43.3788 - val_mse: 43.3788\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 42.8991 - val_mse: 42.8991\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 42.5670 - val_mse: 42.5670\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 42.4767 - val_mse: 42.4767\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.0085 - mse: 0.0085 - val_loss: 42.6103 - val_mse: 42.6103\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 0s 981us/step - loss: 0.0132 - mse: 0.0132 - val_loss: 42.2887 - val_mse: 42.2887\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - 0s 931us/step - loss: 0.0137 - mse: 0.0137 - val_loss: 42.6505 - val_mse: 42.6505\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 0s 981us/step - loss: 0.0103 - mse: 0.0103 - val_loss: 41.2340 - val_mse: 41.2340\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 42.5820 - val_mse: 42.5820\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 42.7703 - val_mse: 42.7703\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 42.0117 - val_mse: 42.0117\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 43.4141 - val_mse: 43.4141\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 43.9348 - val_mse: 43.9348\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 43.0651 - val_mse: 43.0651\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 43.0786 - val_mse: 43.0786\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 42.2527 - val_mse: 42.2527\n",
      "Epoch 31/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 43.8257 - val_mse: 43.8257\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 43.9014 - val_mse: 43.9014\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 44.9481 - val_mse: 44.9481\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 0s 964us/step - loss: 0.0152 - mse: 0.0152 - val_loss: 41.1522 - val_mse: 41.1522\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 0s 997us/step - loss: 0.0118 - mse: 0.0118 - val_loss: 41.8392 - val_mse: 41.8392\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - 0s 964us/step - loss: 0.0053 - mse: 0.0053 - val_loss: 41.9964 - val_mse: 41.9963\n",
      "Epoch 37/100\n",
      "60/60 [==============================] - 0s 931us/step - loss: 0.0054 - mse: 0.0054 - val_loss: 42.5705 - val_mse: 42.5705\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 41.7628 - val_mse: 41.7628\n",
      "Epoch 39/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 41.9924 - val_mse: 41.9924\n",
      "Epoch 40/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 41.1370 - val_mse: 41.1370\n",
      "Epoch 41/100\n",
      "60/60 [==============================] - 0s 981us/step - loss: 0.0049 - mse: 0.0049 - val_loss: 42.8319 - val_mse: 42.8319\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - 0s 914us/step - loss: 0.0043 - mse: 0.0043 - val_loss: 42.5304 - val_mse: 42.5304\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - 0s 914us/step - loss: 0.0068 - mse: 0.0068 - val_loss: 42.6707 - val_mse: 42.6707\n",
      "Epoch 44/100\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.0054 - mse: 0.0054 - val_loss: 42.2675 - val_mse: 42.2675\n",
      "Epoch 45/100\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.0060 - mse: 0.0060 - val_loss: 42.6837 - val_mse: 42.6837\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - 0s 981us/step - loss: 0.0061 - mse: 0.0061 - val_loss: 40.3846 - val_mse: 40.3846\n",
      "Epoch 47/100\n",
      "60/60 [==============================] - 0s 964us/step - loss: 0.0135 - mse: 0.0135 - val_loss: 42.8109 - val_mse: 42.8109\n",
      "Epoch 48/100\n",
      "60/60 [==============================] - 0s 964us/step - loss: 0.0048 - mse: 0.0048 - val_loss: 42.2507 - val_mse: 42.2507\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.0035 - mse: 0.0035 - val_loss: 42.2860 - val_mse: 42.2860\n",
      "Epoch 50/100\n",
      "60/60 [==============================] - 0s 981us/step - loss: 0.0105 - mse: 0.0105 - val_loss: 41.0216 - val_mse: 41.0216\n",
      "Epoch 51/100\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.0063 - mse: 0.0063 - val_loss: 41.3809 - val_mse: 41.3809\n",
      "Epoch 52/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 41.9482 - val_mse: 41.9482\n",
      "Epoch 53/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 40.9383 - val_mse: 40.9383\n",
      "Epoch 54/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 41.8895 - val_mse: 41.8895\n",
      "Epoch 55/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 40.9917 - val_mse: 40.9917\n",
      "Epoch 56/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 41.6265 - val_mse: 41.6265\n",
      "Epoch 57/100\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 41.5025 - val_mse: 41.5025\n",
      "Epoch 58/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 43.4695 - val_mse: 43.4695\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 42.1753 - val_mse: 42.1753\n",
      "Epoch 60/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 41.4338 - val_mse: 41.4338\n",
      "Epoch 61/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 40.5505 - val_mse: 40.5505\n",
      "Epoch 62/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 41.3723 - val_mse: 41.3723\n",
      "Epoch 63/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 40.4542 - val_mse: 40.4542\n",
      "Epoch 64/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 42.0866 - val_mse: 42.0866\n",
      "Epoch 65/100\n",
      "60/60 [==============================] - 0s 981us/step - loss: 0.0018 - mse: 0.0018 - val_loss: 41.3814 - val_mse: 41.3814\n",
      "Epoch 66/100\n",
      "60/60 [==============================] - 0s 931us/step - loss: 0.0017 - mse: 0.0017 - val_loss: 41.5982 - val_mse: 41.5982\n",
      "Epoch 67/100\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.0047 - mse: 0.0047 - val_loss: 41.8775 - val_mse: 41.8775\n",
      "Epoch 68/100\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.0040 - mse: 0.0040 - val_loss: 40.2157 - val_mse: 40.2157\n",
      "Epoch 69/100\n",
      "60/60 [==============================] - 0s 981us/step - loss: 0.0107 - mse: 0.0107 - val_loss: 42.3434 - val_mse: 42.3434\n",
      "Epoch 70/100\n",
      "60/60 [==============================] - 0s 964us/step - loss: 0.0237 - mse: 0.0237 - val_loss: 44.5099 - val_mse: 44.5099\n",
      "Epoch 71/100\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.0403 - mse: 0.0403 - val_loss: 42.2780 - val_mse: 42.2780\n",
      "Epoch 72/100\n",
      "60/60 [==============================] - 0s 914us/step - loss: 0.0603 - mse: 0.0603 - val_loss: 39.1694 - val_mse: 39.1694\n",
      "Epoch 73/100\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.0722 - mse: 0.0722 - val_loss: 42.1373 - val_mse: 42.1373\n",
      "Epoch 74/100\n",
      "60/60 [==============================] - 0s 914us/step - loss: 0.0062 - mse: 0.0062 - val_loss: 40.7133 - val_mse: 40.7133\n",
      "Epoch 75/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 39.4266 - val_mse: 39.4266\n",
      "Epoch 76/100\n",
      "60/60 [==============================] - 0s 964us/step - loss: 0.0165 - mse: 0.0165 - val_loss: 42.0928 - val_mse: 42.0928\n",
      "Epoch 77/100\n",
      "60/60 [==============================] - 0s 931us/step - loss: 0.0040 - mse: 0.0040 - val_loss: 41.2161 - val_mse: 41.2161\n",
      "Epoch 78/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 41.1456 - val_mse: 41.1456\n",
      "Epoch 79/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 41.1064 - val_mse: 41.1064\n",
      "Epoch 80/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 42.8324 - val_mse: 42.8324\n",
      "Epoch 81/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 39.6551 - val_mse: 39.6551\n",
      "Epoch 82/100\n",
      "60/60 [==============================] - 0s 931us/step - loss: 1.7401 - mse: 1.7401 - val_loss: 29.6819 - val_mse: 29.6819\n",
      "Epoch 83/100\n",
      "60/60 [==============================] - 0s 914us/step - loss: 4.7410 - mse: 4.7410 - val_loss: 11.6467 - val_mse: 11.6467\n",
      "Epoch 84/100\n",
      "60/60 [==============================] - 0s 931us/step - loss: 18.6532 - mse: 18.6532 - val_loss: 29.6590 - val_mse: 29.6590\n",
      "Epoch 85/100\n",
      "60/60 [==============================] - 0s 981us/step - loss: 104.4718 - mse: 104.4718 - val_loss: 29.2652 - val_mse: 29.2652\n",
      "Epoch 86/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0455 - mse: 2.0455 - val_loss: 22.0704 - val_mse: 22.0704\n",
      "Epoch 87/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.5717 - mse: 0.5717 - val_loss: 13.6286 - val_mse: 13.6286\n",
      "Epoch 88/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2057 - mse: 0.2057 - val_loss: 10.1744 - val_mse: 10.1744\n",
      "Epoch 89/100\n",
      "60/60 [==============================] - 0s 964us/step - loss: 0.5299 - mse: 0.5299 - val_loss: 8.1579 - val_mse: 8.1579\n",
      "Epoch 90/100\n",
      "60/60 [==============================] - 0s 931us/step - loss: 0.8939 - mse: 0.8939 - val_loss: 10.6828 - val_mse: 10.6828\n",
      "Epoch 91/100\n",
      "60/60 [==============================] - 0s 964us/step - loss: 0.2931 - mse: 0.2931 - val_loss: 14.2351 - val_mse: 14.2351\n",
      "Epoch 92/100\n",
      "60/60 [==============================] - 0s 964us/step - loss: 0.1572 - mse: 0.1572 - val_loss: 14.6944 - val_mse: 14.6944\n",
      "Epoch 93/100\n",
      "60/60 [==============================] - 0s 981us/step - loss: 0.2344 - mse: 0.2344 - val_loss: 17.3940 - val_mse: 17.3940\n",
      "Epoch 94/100\n",
      "60/60 [==============================] - 0s 914us/step - loss: 0.1552 - mse: 0.1552 - val_loss: 13.3031 - val_mse: 13.3031\n",
      "Epoch 95/100\n",
      "60/60 [==============================] - 0s 997us/step - loss: 2.5013 - mse: 2.5013 - val_loss: 30.2603 - val_mse: 30.2603\n",
      "Epoch 96/100\n",
      "60/60 [==============================] - 0s 931us/step - loss: 0.5564 - mse: 0.5564 - val_loss: 16.2375 - val_mse: 16.2375\n",
      "Epoch 97/100\n",
      "60/60 [==============================] - 0s 964us/step - loss: 0.3860 - mse: 0.3860 - val_loss: 17.1839 - val_mse: 17.1839\n",
      "Epoch 98/100\n",
      "60/60 [==============================] - 0s 947us/step - loss: 0.1702 - mse: 0.1702 - val_loss: 12.7771 - val_mse: 12.7771\n",
      "Epoch 99/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.2262 - mse: 0.2262 - val_loss: 9.6882 - val_mse: 9.6882\n",
      "Epoch 100/100\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 0.3559 - mse: 0.3559 - val_loss: 14.7180 - val_mse: 14.7180\n",
      "20/20 [==============================] - 0s 449us/step\n",
      "mse :  [199.31265144348146, 199.31265258789062]\n",
      "[581] [589.17444]\n",
      "[582] [590.75745]\n",
      "[583] [592.34033]\n",
      "[584] [593.9232]\n",
      "[585] [595.50604]\n",
      "[586] [597.0889]\n",
      "[587] [598.67175]\n",
      "[588] [600.25464]\n",
      "[589] [601.8376]\n",
      "[590] [603.4204]\n",
      "[591] [605.00336]\n",
      "[592] [606.5863]\n",
      "[593] [608.16907]\n",
      "[594] [609.752]\n",
      "[595] [611.33484]\n",
      "[596] [612.9177]\n",
      "[597] [614.5007]\n",
      "[598] [616.0835]\n",
      "[599] [617.6664]\n",
      "[600] [619.24927]\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "model.fit([x1_train, x2_train], y_train,\n",
    "epochs=100, batch_size=1,\n",
    "validation_data=([x1_val, x2_val] , y_val))\n",
    "\n",
    "#4. 평가 예측\n",
    "mse = model.evaluate([x1_test, x2_test],\n",
    "y_test, batch_size=1)\n",
    "print(\"mse : \", mse)\n",
    "\n",
    "y_predict = model.predict([x1_test, x2_test])\n",
    "for i in range(len(y_predict)):\n",
    "    print(y_test[i], y_predict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
